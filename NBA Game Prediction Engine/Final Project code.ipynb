{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ad25a9",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Viraj Ajaykumar\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f01bb91-5b04-48ea-a6fc-002f0b2eeadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Found Games Data: games.csv\n",
      "--> Found Players Data: players.csv\n",
      "\n",
      "--- STEP 1: BUILDING DATABASE ---\n",
      "   Database schema created.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "game_file = None\n",
    "player_file = None\n",
    "\n",
    "# 1. Find Games File\n",
    "possible_games = ['games.csv', 'nba_2008-2025.csv', 'archive/nba_2008-2025.csv']\n",
    "for f in possible_games:\n",
    "    if os.path.exists(f):\n",
    "        game_file = f\n",
    "        print(f\"--> Found Games Data: {f}\")\n",
    "        break\n",
    "\n",
    "# 2. Find Players File\n",
    "possible_players = ['players.csv', '01.csv']\n",
    "for f in possible_players:\n",
    "    if os.path.exists(f):\n",
    "        player_file = f\n",
    "        print(f\"--> Found Players Data: {f}\")\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "# PART 1: DATABASE CONSTRUCTION (SQL)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- STEP 1: BUILDING DATABASE ---\")\n",
    "conn = sqlite3.connect('nba_project.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Reset Tables (Start Fresh)\n",
    "cursor.execute('DROP TABLE IF EXISTS games')\n",
    "cursor.execute('DROP TABLE IF EXISTS players')\n",
    "\n",
    "# 1. Create Games Table Schema\n",
    "cursor.execute('''\n",
    "CREATE TABLE games (\n",
    "    game_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    game_date TEXT,\n",
    "    season INTEGER,\n",
    "    home_team TEXT,\n",
    "    away_team TEXT,\n",
    "    home_score INTEGER,\n",
    "    away_score INTEGER,\n",
    "    home_moneyline REAL,\n",
    "    away_moneyline REAL,\n",
    "    spread REAL,\n",
    "    home_win INTEGER\n",
    ")\n",
    "''')\n",
    "\n",
    "# 2. Create Players Table Schema\n",
    "cursor.execute('''\n",
    "CREATE TABLE players (\n",
    "    player_id INTEGER PRIMARY KEY,\n",
    "    player_name TEXT,\n",
    "    team_abbreviation TEXT,\n",
    "    position TEXT,\n",
    "    height TEXT,\n",
    "    weight INTEGER,\n",
    "    age REAL,\n",
    "    experience TEXT\n",
    ")\n",
    "''')\n",
    "conn.commit()\n",
    "print(\"   Database schema created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0e4e1bd-37cc-414f-9eba-65e4efdcf5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 2: LOADING DATA ---\n",
      "   Successfully loaded 19820 games.\n",
      "   Successfully loaded 499 players.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# PART 2: ETL \n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- STEP 2: LOADING DATA ---\")\n",
    "\n",
    "# A. LOAD GAMES\n",
    "try:\n",
    "    df_games = pd.read_csv(game_file)\n",
    "\n",
    "    # Data Cleaning: Drop rows with missing betting odds\n",
    "    df_games = df_games.dropna(subset=['moneyline_home', 'moneyline_away']).copy()\n",
    "\n",
    "    # Feature Engineering: Create Target (Did Home Team Win?)\n",
    "    df_games['home_win'] = (df_games['score_home'] > df_games['score_away']).astype(int)\n",
    "\n",
    "    # Rename Columns to match SQL Table\n",
    "    games_column_map = {\n",
    "        'date': 'game_date', 'season': 'season', 'home': 'home_team', 'away': 'away_team',\n",
    "        'score_home': 'home_score', 'score_away': 'away_score',\n",
    "        'moneyline_home': 'home_moneyline', 'moneyline_away': 'away_moneyline',\n",
    "        'spread': 'spread', 'home_win': 'home_win'\n",
    "    }\n",
    "    # Handle optional column renaming if keys exist\n",
    "    df_games = df_games.rename(columns=games_column_map)\n",
    "    \n",
    "    # Select only the columns we need (intersection with available columns)\n",
    "    available_cols = [c for c in games_column_map.values() if c in df_games.columns]\n",
    "    df_games_final = df_games[available_cols]\n",
    "\n",
    "    # Load into SQL\n",
    "    df_games_final.to_sql('games', conn, if_exists='replace', index=False)\n",
    "    print(f\"   Successfully loaded {len(df_games_final)} games.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   Error loading games: {e}\")\n",
    "\n",
    "# B. LOAD PLAYERS\n",
    "if player_file:\n",
    "    try:\n",
    "        df_players = pd.read_csv(player_file)\n",
    "\n",
    "        # Rename Columns to match SQL Table\n",
    "        players_column_map = {\n",
    "            'PLAYER_ID': 'player_id', 'PLAYER_NAME': 'player_name',\n",
    "            'TEAM_ABBREVIATION': 'team_abbreviation', 'POSITION': 'position',\n",
    "            'HEIGHT': 'height', 'WEIGHT': 'weight',\n",
    "            'AGE': 'age', 'EXPERIENCE': 'experience'\n",
    "        }\n",
    "        df_players = df_players.rename(columns=players_column_map)\n",
    "        \n",
    "        # Handle case-sensitivity (if CSV headers were lowercase)\n",
    "        if 'player_id' not in df_players.columns and 'PLAYER_ID' not in df_players.columns:\n",
    "             # Try forcing all to lowercase match\n",
    "             df_players.columns = [c.lower() for c in df_players.columns]\n",
    "\n",
    "        # Select columns\n",
    "        available_player_cols = [c for c in players_column_map.values() if c in df_players.columns]\n",
    "        df_players_final = df_players[available_player_cols]\n",
    "\n",
    "        # Load into SQL\n",
    "        df_players_final.to_sql('players', conn, if_exists='replace', index=False)\n",
    "        print(f\"   Successfully loaded {len(df_players_final)} players.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Error loading players: {e}\")\n",
    "else:\n",
    "    print(\"   WARNING: No Players file found. Skipping Players table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ce8db1-78f5-4334-bfe4-a54fe1bd832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 3: TRAINING MODEL ---\n",
      "--- DIAGNOSTICS ---\n",
      "Total Rows in 'games' table: 19820\n",
      "Seasons found in DB: [2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021\n",
      " 2022 2023]\n",
      "\n",
      "--- FETCHING DATA FOR ML ---\n",
      "Rows retrieved for training: 19820\n",
      "Splitting data...\n",
      "Training Random Forest...\n",
      "\n",
      "==============================\n",
      "FINAL ACCURACY: 66.17%\n",
      "==============================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56      1687\n",
      "           1       0.68      0.78      0.72      2277\n",
      "\n",
      "    accuracy                           0.66      3964\n",
      "   macro avg       0.65      0.64      0.64      3964\n",
      "weighted avg       0.66      0.66      0.66      3964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# PART 3: MACHINE LEARNING\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"\\n--- STEP 3: TRAINING MODEL ---\")\n",
    "\n",
    "#1. CONNECT TO DATABASE\n",
    "conn = sqlite3.connect('nba_project.db')\n",
    "\n",
    "# --- DIAGNOSTIC CHECK (Debug the empty data) ---\n",
    "print(\"--- DIAGNOSTICS ---\")\n",
    "try:\n",
    "    # Check total rows\n",
    "    count = pd.read_sql(\"SELECT count(*) as cnt FROM games\", conn)['cnt'][0]\n",
    "    print(f\"Total Rows in 'games' table: {count}\")\n",
    "\n",
    "    if count > 0:\n",
    "        # Check seasons\n",
    "        seasons = pd.read_sql(\"SELECT DISTINCT season FROM games ORDER BY season\", conn)\n",
    "        print(f\"Seasons found in DB: {seasons['season'].unique()}\")\n",
    "    else:\n",
    "        print(\"CRITICAL WARNING: The 'games' table is EMPTY. The loading step failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Database Error: {e}\")\n",
    "\n",
    "# 2. FETCH DATA (FIXED: REMOVED DATE FILTER)\n",
    "print(\"\\n--- FETCHING DATA FOR ML ---\")\n",
    "# We removed \"WHERE season >= 2015\" to ensure we get ANY data available\n",
    "query = \"SELECT home_moneyline, away_moneyline, spread, home_win FROM games\"\n",
    "df_model = pd.read_sql(query, conn)\n",
    "\n",
    "print(f\"Rows retrieved for training: {len(df_model)}\")\n",
    "\n",
    "# 3. RUN MACHINE LEARNING (Only if we have data)\n",
    "if len(df_model) > 10:\n",
    "    # Features & Target\n",
    "    X = df_model[['home_moneyline', 'away_moneyline', 'spread']]\n",
    "    y = df_model['home_win']\n",
    "\n",
    "    # Train/Test Split\n",
    "    print(\"Splitting data...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Model Training\n",
    "    print(\"Training Random Forest...\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"FINAL ACCURACY: {accuracy:.2%}\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "else:\n",
    "    print(\"\\nERROR: Not enough data to train a model!\")\n",
    "    print(\"If Total Rows was 0: Your loading script dropped all the rows (maybe columns didn't match?).\")\n",
    "    print(\"If Total Rows was > 0 but Training Rows is 0: Your query column names might be wrong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2d8a8-f8a6-4fe3-a277-03ff91186129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# PART 4: VISUALIZATIONS (COURSE SLIDES)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- STEP 4: GENERATING GRAPHS ---\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Retrieve full data for plotting\n",
    "df_plots = pd.read_sql(\"SELECT * FROM games\", conn)\n",
    "\n",
    "# Re-engineer features for plotting\n",
    "df_plots['margin'] = df_plots['home_score'] - df_plots['away_score']\n",
    "df_plots['total_points'] = df_plots['home_score'] + df_plots['away_score']\n",
    "\n",
    "# --- CRITICAL FIX: CLEANING BEFORE PLOTTING ---\n",
    "# Remove any rows with NaN/Inf in the columns we are about to plot\n",
    "plot_cols = ['spread', 'margin', 'season', 'total_points']\n",
    "df_plots = df_plots.replace([np.inf, -np.inf], np.nan).dropna(subset=plot_cols)\n",
    "\n",
    "if len(df_plots) == 0:\n",
    "    print(\"WARNING: No valid data found for plotting. Skipping graphs.\")\n",
    "else:\n",
    "    # --- PLOT 1: HISTOGRAM (1D Data - Interval) ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df_plots['margin'], bins=30, kde=True, color='purple', edgecolor='black', alpha=0.7)\n",
    "    plt.title('Distribution of Victory Margins (Histogram)', fontsize=16)\n",
    "    plt.xlabel('Point Difference (Positive = Home Win, Negative = Away Win)', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.axvline(0, color='red', linestyle='--', linewidth=2, label='Tie Game')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 2: SCATTER PLOT (2D Data - Relationship) ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_plots['spread'], df_plots['margin'], alpha=0.15, color='green', s=15)\n",
    "    plt.title('Vegas Spread vs. Actual Point Difference (Scatter Plot)', fontsize=16)\n",
    "    plt.xlabel('Vegas Spread (Predicted Margin)', fontsize=12)\n",
    "    plt.ylabel('Actual Margin (Home Score - Away Score)', fontsize=12)\n",
    "    \n",
    "    # Add Trend Line (With Error Handling)\n",
    "    try:\n",
    "        if len(df_plots) > 1:\n",
    "            z = np.polyfit(df_plots['spread'], df_plots['margin'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(df_plots['spread'], p(df_plots['spread']), \"r--\", linewidth=2, label='Trend Line')\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping trend line due to calculation error: {e}\")\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 3: TIME-SERIES LINE PLOT (2D Data - Evolution) ---\n",
    "    season_stats = df_plots.groupby('season')['total_points'].mean().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(data=season_stats, x='season', y='total_points', marker='o', linewidth=3, color='darkblue')\n",
    "    plt.title('The NBA Scoring Explosion: Avg Total Points (2008-2025)', fontsize=16)\n",
    "    plt.xlabel('Season', fontsize=12)\n",
    "    plt.ylabel('Average Combined Score per Game', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 4: CORRELATION HEATMAP (2D Data - Complex Grid) ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    corr_cols = ['home_score', 'away_score', 'home_moneyline', 'away_moneyline', 'spread', 'home_win', 'margin', 'total_points']\n",
    "    # Ensure columns exist before correlation\n",
    "    available_corr_cols = [c for c in corr_cols if c in df_plots.columns]\n",
    "    corr_matrix = df_plots[available_corr_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5, square=True, vmin=-1, vmax=1)\n",
    "    plt.title('Feature Correlation Heatmap', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSUCCESS! Project Execution Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ca8f8-01eb-4005-8ff9-b39be0a950d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
